{"title":"神经架构搜索简介","uid":"c570dc3eddcfb883ac8ac92a0eb2658a","slug":"20210826","date":"2021-08-25T08:48:50.000Z","updated":"2021-08-26T13:44:52.733Z","comments":true,"path":"api/articles/20210826.json","keywords":null,"cover":[],"content":"<p>今天水一天，放一章之前入门 NAS 时做的整理~</p>\n<span id=\"more\"></span>\n<h2 id=\"NAS的三个研究方向\"><a href=\"#NAS的三个研究方向\" class=\"headerlink\" title=\"NAS的三个研究方向\"></a>NAS的三个研究方向</h2><p><img src=\"/post/20210826/1.jpg\" alt=\"NAS的三个研究方向\"></p>\n<ol>\n<li><p>搜索空间</p>\n<ul>\n<li>定义网络的表达形式</li>\n<li>结合特定任务的先验知识，可以减小搜索空间的大小，但同时也引入了人类的偏见，可能会限制人类找到更好的未知结构 </li>\n</ul>\n</li>\n<li><p>搜索策略</p>\n<ul>\n<li>构建模型</li>\n<li>一方面要提高收敛速度，另一方面应该避免过早收敛到次优结构</li>\n</ul>\n</li>\n<li><p>性能评价策略</p>\n<ul>\n<li>直接在数据集上跑模型非常耗时，需要更好的评价策略</li>\n<li>判断模型，反馈给搜索策略，搜索策略根据反馈重新生成模型</li>\n</ul>\n</li>\n</ol>\n<h2 id=\"搜索空间\"><a href=\"#搜索空间\" class=\"headerlink\" title=\"搜索空间\"></a>搜索空间</h2><ol>\n<li><p>链式结构（逐层）</p>\n<ul>\n<li>难点：参数化<ol>\n<li>最大层数（可能无限）</li>\n<li>每层的操作（池化、卷积、……）</li>\n<li>每层操作对应的参数</li>\n</ol>\n</li>\n</ul>\n</li>\n<li><p>多分支网络（逐层）</p>\n<ul>\n<li>每一层的输入是之前层的组合</li>\n<li>特例：<ol>\n<li>链式结构</li>\n<li>Residual Networks（summed）</li>\n<li>DenseNets（concatenated）</li>\n</ol>\n</li>\n</ul>\n</li>\n<li><p>逐块:普通块和归约块、堆叠</p>\n<ul>\n<li>优势：<ol>\n<li>搜索空间减少</li>\n<li>更好迁移（？）</li>\n<li>通过重读构建块来创建体系已经被证明的是很好的设计原则</li>\n</ol>\n</li>\n<li>同时，出现了新的设计选择:<ol>\n<li>微结构和整体结构都要最优</li>\n<li>微结构（可以借鉴现有的经典网络）</li>\n</ol>\n</li>\n</ul>\n</li>\n</ol>\n<h2 id=\"搜索策略\"><a href=\"#搜索策略\" class=\"headerlink\" title=\"搜索策略\"></a>搜索策略</h2><ul>\n<li>基于梯度的算法</li>\n<li>贝叶斯优化</li>\n<li>进化算法</li>\n<li>随机搜索（RS）</li>\n<li>强化学习（RL）</li>\n<li>遗传算法</li>\n</ul>\n<h2 id=\"性能评估\"><a href=\"#性能评估\" class=\"headerlink\" title=\"性能评估\"></a>性能评估</h2><ul>\n<li>低保真度</li>\n<li>曲线外推</li>\n<li>Network Morphism<br>  根据以前训练过的其他架构的权重来初始化新架构的权重</li>\n<li>One-Shot Architecture Search<br>  将所有体系结构视为一个超图的不同子图</li>\n</ul>\n","feature":true,"text":"今天水一天，放一章之前入门 NAS 时做的整理~ NAS的三个研究方向 搜索空间 定义网络的表达形式 结合特定任务的先验知识，可以减小搜索空间的大小，但同时也引入了人类的偏见，可能会限制人类找到更好的未知结构 搜索策略 构建模型 一方面要提高收敛速度，另一方面应该避免过早收敛到次...","link":"","photos":[],"count_time":{"symbolsCount":637,"symbolsTime":"1 mins."},"categories":[{"name":"Review","slug":"Review","count":1,"path":"api/categories/Review.json"}],"tags":[{"name":"NAS","slug":"NAS","count":1,"path":"api/tags/NAS.json"}],"toc":"<ol class=\"toc\"><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#NAS%E7%9A%84%E4%B8%89%E4%B8%AA%E7%A0%94%E7%A9%B6%E6%96%B9%E5%90%91\"><span class=\"toc-text\">NAS的三个研究方向</span></a></li><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#%E6%90%9C%E7%B4%A2%E7%A9%BA%E9%97%B4\"><span class=\"toc-text\">搜索空间</span></a></li><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#%E6%90%9C%E7%B4%A2%E7%AD%96%E7%95%A5\"><span class=\"toc-text\">搜索策略</span></a></li><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#%E6%80%A7%E8%83%BD%E8%AF%84%E4%BC%B0\"><span class=\"toc-text\">性能评估</span></a></li></ol>","author":{"name":"Fairy","slug":"blog-author","avatar":"https://img-blog.csdnimg.cn/20210313122054101.png","link":"/","description":"","socials":{"github":"","twitter":"","stackoverflow":"","wechat":"","qq":"","weibo":"","zhihu":"","csdn":"","juejin":"","customs":{}}},"mapped":true,"prev_post":{"title":"机器学习系列笔记（一）","uid":"127b640a2365c521fe651e857a784559","slug":"20210829","date":"2021-08-29T06:56:50.000Z","updated":"2021-08-29T12:15:44.249Z","comments":true,"path":"api/articles/20210829.json","keywords":null,"cover":[],"text":"最近在训练一个5000个类别的分类模型，每次调参后训练时间都很长，打算听从我导的建议，利用这些碎片时间把深度学习系统地过一遍。主要参考李宏毅和《深度学习》。在这里做一个学习记录便于后续复习参考。 有小伙伴提到评论区无法正常使用的问题，等我后续有空再进行调整，在此之前如果大家对博客...","link":"","photos":[],"count_time":{"symbolsCount":"1.4k","symbolsTime":"1 mins."},"categories":[{"name":"Note","slug":"Note","count":1,"path":"api/categories/Note.json"}],"tags":[{"name":"ML","slug":"ML","count":1,"path":"api/tags/ML.json"}],"author":{"name":"Fairy","slug":"blog-author","avatar":"https://img-blog.csdnimg.cn/20210313122054101.png","link":"/","description":"","socials":{"github":"","twitter":"","stackoverflow":"","wechat":"","qq":"","weibo":"","zhihu":"","csdn":"","juejin":"","customs":{}}},"feature":true},"next_post":{}}