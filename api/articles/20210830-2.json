{"title":"Batch大小对训练的影响","uid":"938697651832116ebe2e74312921919c","slug":"20210830-2","date":"2021-08-30T02:45:00.000Z","updated":"2021-08-31T11:08:49.261Z","comments":true,"path":"api/articles/20210830-2.json","keywords":null,"cover":[],"content":"<p>我们往往将数据集分成多个 batch 传入模型中，batch大小不仅影响着 GPU 的利用率，也影响着模型的训练过程。</p>\n<p>在训练过程中，输入一个 batch ，模型会根据这个 batch 更新一次参数（一次update），也就是说，如果有100个 batch ，模型在每个epoch就会更新100次参数。</p>\n<p><img src=\"/post/20210830-2/batch.jpg\" alt=\"batch\"></p>\n<p>由于GPU的并行加速，在一定范围内，<strong>batch size较大</strong>时，update次数少，速度反而和 batch size 较小时<strong>差不多</strong>。</p>\n<p>但是 batch size 较小时，每一个 batch 的 loss 略有差异， <strong>容易避开局部极值或者鞍点</strong>；此外，<strong>小的 batch size 更容易避开 overfitting</strong>， 这<strong>可能是</strong>因为训练集和测试集的分布可能略有差异, 而小 batch 的 update 次数更多，更倾向于走进平缓地区的局部极值。</p>\n<p><img src=\"/post/20210830-2/small_batch.jpg\" alt=\"small_batch\"></p>\n<p><img src=\"/post/20210830-2/comp.jpg\" alt=\"comp\"></p>\n<h2 id=\"参考资料\"><a href=\"#参考资料\" class=\"headerlink\" title=\"参考资料\"></a>参考资料</h2><p>一些在大的batch下提高模型表现的方法。</p>\n<p><img src=\"/post/20210830-2/methods.jpg\" alt=\"methods\"></p>\n","text":"我们往往将数据集分成多个 batch 传入模型中，batch大小不仅影响着 GPU 的利用率，也影响着模型的训练过程。 在训练过程中，输入一个 batch ，模型会根据这个 batch 更新一次参数（一次update），也就是说，如果有100个 batch ，模型在每个epoch...","link":"","photos":[],"count_time":{"symbolsCount":403,"symbolsTime":"1 mins."},"categories":[{"name":"Note","slug":"Note","count":8,"path":"api/categories/Note.json"}],"tags":[{"name":"DL","slug":"DL","count":4,"path":"api/tags/DL.json"}],"toc":"<ol class=\"toc\"><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#%E5%8F%82%E8%80%83%E8%B5%84%E6%96%99\"><span class=\"toc-text\">参考资料</span></a></li></ol>","author":{"name":"Fairy","slug":"blog-author","avatar":"https://img-blog.csdnimg.cn/20210313122054101.png","link":"/","description":"","socials":{"github":"","twitter":"","stackoverflow":"","wechat":"","qq":"","weibo":"","zhihu":"","csdn":"","juejin":"","customs":{}}},"mapped":true,"prev_post":{"title":"深度学习应该有多深","uid":"9fe013286807d555c32ac577b233a122","slug":"20210830-3","date":"2021-08-30T02:45:00.000Z","updated":"2021-08-30T14:33:52.738Z","comments":true,"path":"api/articles/20210830-3.json","keywords":null,"cover":null,"text":"深度和宽度是一样的吗？深度越深越好吗？","link":"","photos":[],"count_time":{"symbolsCount":19,"symbolsTime":"1 mins."},"categories":[{"name":"Note","slug":"Note","count":8,"path":"api/categories/Note.json"}],"tags":[{"name":"DL","slug":"DL","count":4,"path":"api/tags/DL.json"}],"author":{"name":"Fairy","slug":"blog-author","avatar":"https://img-blog.csdnimg.cn/20210313122054101.png","link":"/","description":"","socials":{"github":"","twitter":"","stackoverflow":"","wechat":"","qq":"","weibo":"","zhihu":"","csdn":"","juejin":"","customs":{}}}},"next_post":{"title":"机器学习系列笔记（一）","uid":"127b640a2365c521fe651e857a784559","slug":"20210829","date":"2021-08-29T06:56:50.000Z","updated":"2021-08-30T14:34:02.052Z","comments":true,"path":"api/articles/20210829.json","keywords":null,"cover":[],"text":"最近在训练一个5000个类别的分类模型，每次调参后训练时间都很长，打算听从我导的建议，利用这些碎片时间把深度学习系统地过一遍。主要参考李宏毅和《深度学习》。在这里做一个学习记录便于后续复习参考。 有小伙伴提到评论区无法正常使用的问题，等我后续有空再进行调整，在此之前如果大家对博客...","link":"","photos":[],"count_time":{"symbolsCount":"1.6k","symbolsTime":"1 mins."},"categories":[{"name":"Note","slug":"Note","count":8,"path":"api/categories/Note.json"}],"tags":[{"name":"ML","slug":"ML","count":3,"path":"api/tags/ML.json"}],"author":{"name":"Fairy","slug":"blog-author","avatar":"https://img-blog.csdnimg.cn/20210313122054101.png","link":"/","description":"","socials":{"github":"","twitter":"","stackoverflow":"","wechat":"","qq":"","weibo":"","zhihu":"","csdn":"","juejin":"","customs":{}}}}}