{"title":"计算机视觉课堂笔记（一）","uid":"9b3d86264880822e8087460a73411fbe","slug":"20210914-CV-1","date":"2021-09-14T08:00:00.000Z","updated":"2021-09-17T14:09:24.167Z","comments":true,"path":"api/articles/20210914-CV-1.json","keywords":null,"cover":null,"content":"<table>\n   <tr>\n      <td rowspan=\"3\">组合优化</td>\n      <td>确定性算法</td>\n      <td> ... </td>\n   </tr>\n   <tr>\n      <td rowspan=\"2\">非确定性算法</td>\n      <td>随机算法 </td>\n      <td>拉斯维加斯算法、蒙特卡洛算法 </td>\n   </tr>\n   <tr>\n      <td>近似算法</td>\n      <td colspan=\"2\">...</td>\n   </tr>\n   <tr>\n      <td>连续优化</td>\n      <td colspan=\"3\">...</td>\n   </tr>\n</table>\n\n<h2 id=\"组合优化-amp-连续优化\"><a href=\"#组合优化-amp-连续优化\" class=\"headerlink\" title=\"组合优化 &amp; 连续优化\"></a>组合优化 &amp; 连续优化</h2><ol>\n<li>连续优化求解连续变量的问题</li>\n<li>组合优化（离散）优化求解离散变量问题</li>\n</ol>\n<h2 id=\"确定性算法-amp-非确定性算法\"><a href=\"#确定性算法-amp-非确定性算法\" class=\"headerlink\" title=\"确定性算法 &amp; 非确定性算法\"></a>确定性算法 &amp; 非确定性算法</h2><ol>\n<li>确定性算法：对于一个算法，给定当前的状态和输入，该算法<strong>只有一个</strong>动作可供选择</li>\n<li>非确定性算法：对于一个算法，给定当前的状态和输入，该算法<strong>有多个</strong>动作可供选择（随机算法）</li>\n</ol>\n<h2 id=\"时间复杂度\"><a href=\"#时间复杂度\" class=\"headerlink\" title=\"时间复杂度\"></a>时间复杂度</h2><p>$O(n) &gt; O(\\sqrt{n}) &gt; O(\\log{n}) &gt; O(1) $</p>\n<h2 id=\"并查集\"><a href=\"#并查集\" class=\"headerlink\" title=\"并查集\"></a>并查集</h2><p>并查集的时间复杂度：<a href=\"https://en.wikipedia.org/wiki/Disjoint-set_data_structure#Proof_of_O(log*(n\">$O(log^*n)$</a>)_time_complexity_of_Union-Find), 逼近$O(1)$，但是比$O(1)$慢一点。</p>\n<h2 id=\"搜索算法\"><a href=\"#搜索算法\" class=\"headerlink\" title=\"搜索算法\"></a>搜索算法</h2><h3 id=\"分治法\"><a href=\"#分治法\" class=\"headerlink\" title=\"分治法\"></a>分治法</h3><p>分治法将原问题分解为若干个<strong>规模较小但类似于原问题的</strong>子问题，求解这些子问题，然后再合并子问题。</p>\n<h3 id=\"动态规划\"><a href=\"#动态规划\" class=\"headerlink\" title=\"动态规划\"></a>动态规划</h3><p>动态规划也是将原问题分解为若干个<strong>规模较小但类似于原问题的</strong>子问题，求解这些子问题，然后再合并子问题。不同的是，<strong>子问题之间会有重叠</strong>，即一个子问题被求解后，可能会再次求解，因此可以把子问题的解存储起来。</p>\n<p>常见的动态规划：Floyd算法</p>\n<h3 id=\"贪心算法\"><a href=\"#贪心算法\" class=\"headerlink\" title=\"贪心算法\"></a>贪心算法</h3><p>在每一步都做出当前的最优选择。当问题具有贪心选择性质的时候可以使用贪心算法来解决。</p>\n<p><strong>贪心选择性质</strong>：可以通过局部最优来构造全局最优。</p>\n<p>常见的贪心算法：迪杰斯特拉算法</p>\n<h3 id=\"主定理\"><a href=\"#主定理\" class=\"headerlink\" title=\"主定理\"></a>主定理</h3><p>主定理是一种快速得出递归问题的时间复杂度的方法。</p>\n<p>假设某个递归算法的时间复杂度递归公式为：</p>\n<p>$T(n) = a*T(\\frac {n}{b})+n^d$，其中，$a&gt;1$, $b&gt;1$, $d&gt;0$, 这个表达式其实是在表达：将规模为n 的问题转换为$a$个规模为 $\\frac{n}{b}$的子问题，在合并这些子问题的解时需要花费$O(n^{d})$时间。</p>\n<p><em>TBC</em></p>\n","feature":true,"text":" 组合优化 确定性算法 ... 非确定性算法 随机算法 拉斯维加斯算法、蒙特卡洛算法 近似算法 ... 连续优化 ... 组合优化 &amp; 连续优化 连续优化求解连续变量的问题 组合优化（离散）优化求解离散变量问题 确定性算法 &amp; 非确定性算法 确定性算法：对于一个算...","link":"","photos":[],"count_time":{"symbolsCount":903,"symbolsTime":"1 mins."},"categories":[{"name":"Note","slug":"Note","count":8,"path":"api/categories/Note.json"}],"tags":[{"name":"CV","slug":"CV","count":1,"path":"api/tags/CV.json"}],"toc":"<ol class=\"toc\"><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#%E7%BB%84%E5%90%88%E4%BC%98%E5%8C%96-amp-%E8%BF%9E%E7%BB%AD%E4%BC%98%E5%8C%96\"><span class=\"toc-text\">组合优化 &amp; 连续优化</span></a></li><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#%E7%A1%AE%E5%AE%9A%E6%80%A7%E7%AE%97%E6%B3%95-amp-%E9%9D%9E%E7%A1%AE%E5%AE%9A%E6%80%A7%E7%AE%97%E6%B3%95\"><span class=\"toc-text\">确定性算法 &amp; 非确定性算法</span></a></li><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#%E6%97%B6%E9%97%B4%E5%A4%8D%E6%9D%82%E5%BA%A6\"><span class=\"toc-text\">时间复杂度</span></a></li><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#%E5%B9%B6%E6%9F%A5%E9%9B%86\"><span class=\"toc-text\">并查集</span></a></li><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#%E6%90%9C%E7%B4%A2%E7%AE%97%E6%B3%95\"><span class=\"toc-text\">搜索算法</span></a><ol class=\"toc-child\"><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#%E5%88%86%E6%B2%BB%E6%B3%95\"><span class=\"toc-text\">分治法</span></a></li><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#%E5%8A%A8%E6%80%81%E8%A7%84%E5%88%92\"><span class=\"toc-text\">动态规划</span></a></li><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#%E8%B4%AA%E5%BF%83%E7%AE%97%E6%B3%95\"><span class=\"toc-text\">贪心算法</span></a></li><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#%E4%B8%BB%E5%AE%9A%E7%90%86\"><span class=\"toc-text\">主定理</span></a></li></ol></li></ol>","author":{"name":"Fairy","slug":"blog-author","avatar":"https://img-blog.csdnimg.cn/20210313122054101.png","link":"/","description":"","socials":{"github":"","twitter":"","stackoverflow":"","wechat":"","qq":"","weibo":"","zhihu":"","csdn":"","juejin":"","customs":{}}},"mapped":true,"prev_post":{},"next_post":{"title":"模式识别课堂笔记（一）","uid":"cd4402c8b1b8d0463e3fafdd26dfaa95","slug":"20210914-Pattern-recognition-1","date":"2021-09-14T06:00:00.000Z","updated":"2021-09-14T07:44:21.672Z","comments":true,"path":"api/articles/20210914-Pattern-recognition-1.json","keywords":null,"cover":null,"text":"模式识别和机器学习的区别在于：前者喂给机器的是各种特征描述，从而让机器对未知的事物进行判断；后者喂给机器的是某一事物的海量样本，让机器通过样本来自己发现特征，最后去判断某些未知的事物。 贝叶斯规则公式 ","link":"","photos":[],"count_time":{"symbolsCount":101,"symbolsTime":"1 mins."},"categories":[{"name":"Note","slug":"Note","count":8,"path":"api/categories/Note.json"}],"tags":[{"name":"Pattern Recognition","slug":"Pattern-Recognition","count":1,"path":"api/tags/Pattern-Recognition.json"}],"author":{"name":"Fairy","slug":"blog-author","avatar":"https://img-blog.csdnimg.cn/20210313122054101.png","link":"/","description":"","socials":{"github":"","twitter":"","stackoverflow":"","wechat":"","qq":"","weibo":"","zhihu":"","csdn":"","juejin":"","customs":{}}},"feature":true}}