{"name":"机器学习","slug":"机器学习","count":4,"postlist":[{"title":"机器学习系列笔记（一）","uid":"127b640a2365c521fe651e857a784559","slug":"20210829","date":"2021-08-29T06:56:50.000Z","updated":"2021-09-18T12:51:07.655Z","comments":true,"path":"api/articles/20210829.json","keywords":null,"cover":[],"text":"最近在训练一个5000个类别的分类模型，每次调参后训练时间都很长，打算听从我导的建议，利用这些碎片时间把深度学习系统地过一遍。主要参考李宏毅和《深度学习》。在这里做一个学习记录便于后续复习参考。 有小伙伴提到评论区无法正常使用的问题，等我后续有空再进行调整，在此之前如果大家对博客...","link":"","photos":[],"count_time":{"symbolsCount":"1.6k","symbolsTime":"1 mins."},"categories":[{"name":"机器学习","slug":"机器学习","count":4,"path":"api/categories/机器学习.json"}],"tags":[{"name":"Note","slug":"Note","count":7,"path":"api/tags/Note.json"}],"author":{"name":"Fairy","slug":"blog-author","avatar":"https://img-blog.csdnimg.cn/20210313122054101.png","link":"/","description":"","socials":{"github":"","twitter":"","stackoverflow":"","wechat":"","qq":"","weibo":"","zhihu":"","csdn":"","juejin":"","customs":{}}}},{"title":"机器学习常用公式、概念","uid":"e2d1347c7877fd7ee4f5b998819e7fec","slug":"20210830-1","date":"2021-08-30T02:45:00.000Z","updated":"2021-09-18T12:50:56.759Z","comments":true,"path":"api/articles/20210830-1.json","keywords":null,"cover":null,"text":"本文对比总结在机器学习和深度学习中常见的概念和公式，以备查阅。 持续更新。 LOSSMAE: Mean Absolute Error, 差的绝对值 MAE：Mean Square Error, 差的平方 Cross-entropy： 交叉熵 激活函数SigmoidReLU","link":"","photos":[],"count_time":{"symbolsCount":137,"symbolsTime":"1 mins."},"categories":[{"name":"机器学习","slug":"机器学习","count":4,"path":"api/categories/机器学习.json"}],"tags":[{"name":"公式","slug":"公式","count":1,"path":"api/tags/公式.json"}],"author":{"name":"Fairy","slug":"blog-author","avatar":"https://img-blog.csdnimg.cn/20210313122054101.png","link":"/","description":"","socials":{"github":"","twitter":"","stackoverflow":"","wechat":"","qq":"","weibo":"","zhihu":"","csdn":"","juejin":"","customs":{}}}},{"title":"Batch大小对训练的影响","uid":"938697651832116ebe2e74312921919c","slug":"20210830-2","date":"2021-08-30T02:45:00.000Z","updated":"2021-09-18T12:50:44.949Z","comments":true,"path":"api/articles/20210830-2.json","keywords":null,"cover":[],"text":"我们往往将数据集分成多个 batch 传入模型中，batch大小不仅影响着 GPU 的利用率，也影响着模型的训练过程。 在训练过程中，输入一个 batch ，模型会根据这个 batch 更新一次参数（一次update），也就是说，如果有100个 batch ，模型在每个epoch...","link":"","photos":[],"count_time":{"symbolsCount":403,"symbolsTime":"1 mins."},"categories":[{"name":"机器学习","slug":"机器学习","count":4,"path":"api/categories/机器学习.json"}],"tags":[{"name":"Note","slug":"Note","count":7,"path":"api/tags/Note.json"}],"author":{"name":"Fairy","slug":"blog-author","avatar":"https://img-blog.csdnimg.cn/20210313122054101.png","link":"/","description":"","socials":{"github":"","twitter":"","stackoverflow":"","wechat":"","qq":"","weibo":"","zhihu":"","csdn":"","juejin":"","customs":{}}}},{"title":"机器学习系列笔记（二）","uid":"4c9f78b6f353deae14a5acac20919d3f","slug":"20210831","date":"2021-08-31T09:41:00.000Z","updated":"2021-09-18T12:50:13.871Z","comments":true,"path":"api/articles/20210831.json","keywords":null,"cover":[],"text":"这一部分讨论 Optimization 如果在梯度下降中，当 loss 已经稳定，但还没有达到期望值时，或者 loss 根本不下降，应该怎么做？ 原因猜想：loss 对参数的梯度变成了0（Critical point） 鞍点（Saddle point） 局部极值 鞍点如果是鞍点，...","link":"","photos":[],"count_time":{"symbolsCount":595,"symbolsTime":"1 mins."},"categories":[{"name":"机器学习","slug":"机器学习","count":4,"path":"api/categories/机器学习.json"}],"tags":[{"name":"Note","slug":"Note","count":7,"path":"api/tags/Note.json"}],"author":{"name":"Fairy","slug":"blog-author","avatar":"https://img-blog.csdnimg.cn/20210313122054101.png","link":"/","description":"","socials":{"github":"","twitter":"","stackoverflow":"","wechat":"","qq":"","weibo":"","zhihu":"","csdn":"","juejin":"","customs":{}}}}]}