[{"id":"b9663f58f18133b35bfe243f3e916a80","title":"Hello World","content":"My first blog!\n\n本拖延癌晚期患者终于搭建了自己的博客框架 ~尽量日更~\n","slug":"20210825","date":"2021-08-25T08:48:50.000Z","categories_index":"Diary","tags_index":"Thinking","author_index":"Fairy"},{"id":"c570dc3eddcfb883ac8ac92a0eb2658a","title":"神经架构搜索简介","content":"今天水一天，放一章之前入门 NAS 时做的整理~\n\n\nNAS的三个研究方向\n\n搜索空间\n\n定义网络的表达形式\n结合特定任务的先验知识，可以减小搜索空间的大小，但同时也引入了人类的偏见，可能会限制人类找到更好的未知结构 \n\n\n搜索策略\n\n构建模型\n一方面要提高收敛速度，另一方面应该避免过早收敛到次优结构\n\n\n性能评价策略\n\n直接在数据集上跑模型非常耗时，需要更好的评价策略\n判断模型，反馈给搜索策略，搜索策略根据反馈重新生成模型\n\n\n\n搜索空间\n链式结构（逐层）\n\n难点：参数化\n最大层数（可能无限）\n每层的操作（池化、卷积、……）\n每层操作对应的参数\n\n\n\n\n多分支网络（逐层）\n\n每一层的输入是之前层的组合\n特例：\n链式结构\nResidual Networks（summed）\nDenseNets（concatenated）\n\n\n\n\n逐块:普通块和归约块、堆叠\n\n优势：\n搜索空间减少\n更好迁移（？）\n通过重读构建块来创建体系已经被证明的是很好的设计原则\n\n\n同时，出现了新的设计选择:\n微结构和整体结构都要最优\n微结构（可以借鉴现有的经典网络）\n\n\n\n\n\n搜索策略\n基于梯度的算法\n贝叶斯优化\n进化算法\n随机搜索（RS）\n强化学习（RL）\n遗传算法\n\n性能评估\n低保真度\n曲线外推\nNetwork Morphism  根据以前训练过的其他架构的权重来初始化新架构的权重\nOne-Shot Architecture Search  将所有体系结构视为一个超图的不同子图\n\n","slug":"20210826","date":"2021-08-25T08:48:50.000Z","categories_index":"Review","tags_index":"NAS","author_index":"Fairy"}]